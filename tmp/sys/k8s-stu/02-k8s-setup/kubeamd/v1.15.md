# 概述
kubeadm安装kubenetes  v1.15.x

- centos7
- kubeadm/kubelet/kubectl v1.15.12
- rancher v2.3.5
- calico  v3.14.1

# 环境规划
| 系统 | 配置 | 服务 | 节点 |
| :----: | :----: | :----: | :----: | 
| centos7 | 2c4g | kuberadm/kubectl/kubelet/rancher | master
|  centos7 | 2c4g | kubeadm/kubelet | work-noder

#kubeadm设计
[link](https://github.com/kubernetes/kubeadm/blob/master/docs/design/design_v1.10.md)

[changelog](https://github.com/kubernetes/kubernetes/tree/master/CHANGELOG)

[changelog_v1.15](https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.15.md)

>kubernets v1.15.12  
v1.13+ 支持国内aliyun容器镜像拉取

#kubeadm部署  
kubeadm方式部署，k8s可以把k8s自身的大部分应用管控起来，即运行于pod上，但是kubelet和docker不能这样实现自托管，这两个主机运行为守护进程，因此，只需要在所有主机都安装kubelet和docker,构建k8s集群
相当于是自举。etcd也是托管于pod上运行，使用kubeadm进行部署，安装过程相对简单。这些`主件的pod一般为静态pod(不属于k8s管理)`
通过kubeadm init完成集群master节点的初始化，用kubeadm join加入集群

## 01、准备工作
关闭防火墙和selinux/hosts/ntp
禁用swap
服务器配置，至少2核2G
```
swapoff -a  && /etc/fstab 
mount -a
```

#所有节点
```
cat >/etc/sysctl.d/k8s.conf <<EOF
net.bridge.bridge-nf-call-iptables = 1
net.bridge.bridge-nf-call-iptables=1
net.bridge.bridge-nf-call-ip6tables=1
net.ipv4.ip_forward=1
vm.swappiness=0
EOF

sysctl --system  &&  sysctl -p
```

>#hostname 只能有-/.特殊字符，防止coredns解析不了

## 02、配置yum源及安装
#yum_mirrors
```
wget -O /etc/yum.repos.d/docker-ce.repo  https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo

cat>/etc/yum.repos.d/kubrenetes.repo<<EOF
[kubernetes]
name=Kubernetes Repo
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
gpgcheck=0
gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg
EOF

yum clean all && yum makecache
```

#install docker/kuberamd  
#docker-ce
```
//查看docker-ce版本
yum list docker-ce  --showduplicates |sort -r

//k8s1.14最高支持18.09版本的docker
yum install -y --setopt=obsoletes=0 docker-ce-18.09.6-3.el7

//docker-hub-mirrors
mkdir -p /etc/docker
tee <<EOF >/etc/docker/daemon.json
{
 "registry-mirrors": ["https://eyg9yi6d.mirror.aliyuncs.com"]
}
EOF

systemctl enable docker && systemctl start docker
```

#kubeadm/kubelet/kubectl
```
yum list kubeadm  --showduplicates |sort -r |grep 1.15

#master-node
yum install -y kubelet-1.15.12 kubeadm-1.15.12 kubectl-1.15.12

#work-node
yum install -y kubelet-1.15.12 kubeadm-1.15.12
注意：kubeadm/kubectl/kubelet/kubernetes 版本一致

#配置文件
[root@c-3-102 ~]# rpm -ql kubelet
/etc/kubernetes/manifests
/etc/sysconfig/kubelet
/usr/bin/kubelet
/usr/lib/systemd/system/kubelet.service

#all-nodes-actions
systemctl enable kubelet && systemctl restart kubelet

[root@c-3-102 ~]# kubeadm version -o yaml
clientVersion:
  buildDate: "2020-05-06T05:15:30Z"
  compiler: gc
  gitCommit: e2a822d9f3c2fdb5c9bfbe64313cf9f657f0a725
  gitTreeState: clean
  gitVersion: v1.15.12
  goVersion: go1.12.17
  major: "1"
  minor: "15"
  platform: linux/amd64
```

## 03、kubeadm初始化及work-node加入及CNI
```
//默认需要用到的images保持跟kubeadm版本保持一致
[root@c-3-102 ~]# kubeadm config images list 
headers)W0614 14:12:22.037811    2024 version.go:99] falling back to the local client version: v1.15.12

k8s.gcr.io/kube-apiserver:v1.15.12
k8s.gcr.io/kube-controller-manager:v1.15.12
k8s.gcr.io/kube-scheduler:v1.15.12
k8s.gcr.io/kube-proxy:v1.15.12
k8s.gcr.io/pause:3.1
k8s.gcr.io/etcd:3.3.10
k8s.gcr.io/coredns:1.3.1

kubeadm init \
  --kubernetes-version=v1.15.12 \
  --image-repository registry.aliyuncs.com/google_containers \
  --pod-network-cidr=10.10.0.0/16 \
  --service-cidr=10.20.0.0/16
```

#kubectl 配置
```
mkdir -p $HOME/.kube
cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
chown $(id -u):$(id -g) $HOME/.kube/config
```

#cni-calico
```
//one to end
kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml

//calico
wget https://docs.projectcalico.org/v3.7/manifests/calico.yaml

//change default_cidr
sed -i "s#192.168.0.0/16#10.10.0.0/16#g" calico.yaml

//apply calica.yaml
kubectl  apply -f calico.yaml
```

>注意：calico启动比较慢需要几分钟
```
You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/
```
>cni 容器网络不安装k8s node NotReady,pods core-dns pengding


#work-node
```
kubeadm join 192.168.3.102:6443 --token lcxkjk.x4o510x6tk4xxhps \
    --discovery-token-ca-cert-hash sha256:46d703f2242956b9d333d4d68d7a814bf5896148682e2d5301dd9b5195ada4a7 
```
>注意:默认生成的join-token 24h,后续再加入节点需要重新生成join token

#init流程
```
[kubelet-start] 生成kubelet的配置文件/var/lib/kubelet/config.yaml
[certificates]生成相关的各种证书
[kubeconfig]生成相关的kubeconfig文件
[bootstraptoken]生成token记录下来，后边使用kubeadm join往集群中添加节点时会用到
```

## 04、 k8s-status-check
```
[root@c-3-102 ~]# kubectl get cs   //获取k8s组件状态
NAME                 STATUS    MESSAGE             ERROR
scheduler            Healthy   ok                  
controller-manager   Healthy   ok                  
etcd-0               Healthy   {"health":"true"}   
[root@c-3-102 ~]# 
[root@c-3-102 ~]# kubectl get nodes  //节点状态
NAME      STATUS   ROLES    AGE   VERSION
c-3-102   Ready    master   21m   v1.15.12
c-3-103   Ready    <none>   19m   v1.15.12

[root@c-3-102 ~]# kubectl get pods,svc,deployment

NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.20.0.1    <none>        443/TCP   21m

[root@c-3-102 ~]# kubectl get pods,svc,deployment -A
NAMESPACE     NAME                                           READY   STATUS    RESTARTS   AGE
kube-system   pod/calico-kube-controllers-59757ccf85-gjjbx   1/1     Running   0          17m
kube-system   pod/calico-node-t68fs                          1/1     Running   0          17m
kube-system   pod/calico-node-x28vn                          1/1     Running   0          17m
kube-system   pod/coredns-94d74667-mntdl                     1/1     Running   0          21m
kube-system   pod/coredns-94d74667-vmv42                     1/1     Running   0          21m
kube-system   pod/etcd-c-3-102                               1/1     Running   0          20m
kube-system   pod/kube-apiserver-c-3-102                     1/1     Running   0          20m
kube-system   pod/kube-controller-manager-c-3-102            1/1     Running   2          20m
kube-system   pod/kube-proxy-k9lkh                           1/1     Running   0          19m
kube-system   pod/kube-proxy-s2qqr                           1/1     Running   0          21m
kube-system   pod/kube-scheduler-c-3-102                     1/1     Running   2          20m

NAMESPACE     NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)                  AGE
default       service/kubernetes   ClusterIP   10.20.0.1    <none>        443/TCP                  21m
kube-system   service/kube-dns     ClusterIP   10.20.0.10   <none>        53/UDP,53/TCP,9153/TCP   21m

NAMESPACE     NAME                                            READY   UP-TO-DATE   AVAILABLE   AGE
kube-system   deployment.extensions/calico-kube-controllers   1/1     1            1           17m
kube-system   deployment.extensions/coredns                   2/2     2            2           21m
[root@c-3-102 ~]# 
```

## 05、k8s-testing
```
//testing dns
[root@c-3-102 ~]# kubectl run -it  curl --image=radial/busyboxplus:curl
kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-
pod/v1 or kubectl create instead.If you don't see a command prompt, try pressing enter.

[ root@curl-6bf6db5c4f-4xx25:/ ]$ nslookup kubernetes.default
Server:    10.20.0.10   //kube-dns
Address 1: 10.20.0.10 kube-dns.kube-system.svc.cluster.local

Name:      kubernetes.default  //kube-apiservers
Address 1: 10.20.0.1 kubernetes.default.svc.cluster.local
```

## 06、kubectl-completion
```
[root@c-3-102 ~]# kubectl completion -h

01、add packages
[root@c-3-102 ~]# yum install -y bash-completion

02、write && env
kubectl completion bash > ~/.kube/completion.bash.inc

tee <<EOF >>.bash_profile
#add kubectl completion
source ~/.kube/completion.bash.inc
EOF
```
>关闭再打开ssh terminal

## kubernetes-dashboard
https://github.com/kubernetes/dashboard/releases/tag/v2.0.0-beta3

#download yaml
```
[root@c-3-102 ui]# wget --no-check-certificate -O recommended.yaml  https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-beta3/aio/deploy/recommended.yaml
```

#set nodeport/token-ttl
```
[root@c-3-104 ~]# cat recommended.yaml 

---

kind: Service
apiVersion: v1
metadata:
  labels:
    k8s-app: kubernetes-dashboard
  name: kubernetes-dashboard
  namespace: kubernetes-dashboard
spec:
  type: NodePort   //add
  ports:
    - port: 443
      targetPort: 8443
      nodePort: 30000  //add
  selector:
    k8s-app: kubernetes-dashboard

---
    spec:
      containers:
        - name: kubernetes-dashboard
          image: kubernetesui/dashboard:v2.0.1
          imagePullPolicy: Always
          ports:
            - containerPort: 8443
              protocol: TCP
          args:
            - --auto-generate-certificates
            - --namespace=kubernetes-dashboard
            - --token-ttl=43200   //add
```
#替换国内源加速下载containers
```
//国内k8s
registry.aliyuncs.com/google_containers
kubernetesui  //替换国内地址

sed -i 's#kubernetesui#registry.aliyuncs.com/google_containers#g' recommended.yaml
```
#apply on k8s
```
kubectl create -f recommended.yaml
//check pods 
[root@c-3-102 ui]# kubectl get pods -A
NAMESPACE              NAME                                         READY   STATUS    RESTARTS   AGE
default                curl-6bf6db5c4f-4xx25                        1/1     Running   1          70m
kube-system            calico-kube-controllers-59757ccf85-gjjbx     1/1     Running   0          90m
kube-system            calico-node-t68fs                            1/1     Running   0          90m
kube-system            calico-node-x28vn                            1/1     Running   0          90m
kube-system            coredns-94d74667-mntdl                       1/1     Running   0          94m
kube-system            coredns-94d74667-vmv42                       1/1     Running   0          94m
kube-system            etcd-c-3-102                                 1/1     Running   0          93m
kube-system            kube-apiserver-c-3-102                       1/1     Running   0          93m
kube-system            kube-controller-manager-c-3-102              1/1     Running   2          93m
kube-system            kube-proxy-k9lkh                             1/1     Running   0          93m
kube-system            kube-proxy-s2qqr                             1/1     Running   0          94m
kube-system            kube-scheduler-c-3-102                       1/1     Running   2          94m
kubernetes-dashboard   dashboard-metrics-scraper-6cbcff8d57-c2wzh   1/1     Running   0          43s
kubernetes-dashboard   kubernetes-dashboard-6fd5d88555-9k2ql        1/1     Running   0          43s
[root@c-3-102 ui]# 
```
#grant rbac
```
//step1  createa user
kubectl create serviceaccount  dashboard-admin -n kubernetes-dashboard

//step2  rolebinding 
kubectl create clusterrolebinding  dashboard-admin --clusterrole=cluster-admin --serviceaccount=kubernetes-dashboard:dashboard-admin

//step3  view dashboard-admin token
kubectl describe secrets -n kubernetes-dashboard $(kubectl -n kubernetes-dashboard get secret | awk '/dashboard-admin/{print $1}')

[root@c-3-102 ~]# kubectl get serviceaccount -n kubernetes-dashboard
NAME                   SECRETS   AGE
dashboard-admin        1         37m
default                1         58m
kubernetes-dashboard   1         58m
```

#one to end 
```
kubectl create clusterrolebinding dashboard-admin \
  --clusterrole=cluster-admin \
  --user=system:serviceaccount:kubernetes-dashboard:dashboard-admin

//删除
kubectl delete clusterrolebinding  dashboard-admin
```

#查看dashboard token
```
//view dashboard-admin token

kubectl describe secrets -n kubernetes-dashboard $(kubectl -n kubernetes-dashboard get secret | awk '/dashboard-admin/{print $1}')
```

# kubernetes-dashboard ssl过期
[reference_link](https://www.jianshu.com/p/8021285cc37d)

>Chrome上打开kubernetes dashboard，默认此版本tls过期

#查看dashboard 日志
```
[root@c-3-102 ~]# kubectl get pods -n kubernetes-dashboard 
NAME                                         READY   STATUS    RESTARTS   AGE
dashboard-metrics-scraper-6cbcff8d57-c2wzh   1/1     Running   0          34m
kubernetes-dashboard-6fd5d88555-kcfff        1/1     Running   0          4m34s
[root@c-3-102 ~]# 
[root@c-3-102 ~]# kubectl logs -n kubernetes-dashboard -f pods/kubernetes-dashboard-6fd5d88555-kcfff
```

#dashboard pod日志
```
2020/06/14 07:52:38 http: TLS handshake error from 192.168.3.102:54193: remote error: tls: unknown certificate
2020/06/14 07:52:38 http: TLS handshake error from 192.168.3.102:54194: remote error: tls: unknown certificate
```

#更新kubenetes-dashboard ssl证书
```
[root@c-3-102 ~]# mkdir key && cd key
[root@c-3-102 key]# openssl genrsa -out dashboard.key 2048

[root@c-3-102 key]# openssl req -new -out dashboard.csr -key dashboard.key -subj '/CN=cn'

[root@c-3-102 key]# openssl x509 -req -in dashboard.csr -signkey dashboard.key -out dashboard.crt
```

#更新k8s-secrets
```
//查看certs
[root@c-3-102 ~]# kubectl get secrets -n kubernetes-dashboard  
NAME                               TYPE                                  DATA   AGE
dashboard-admin-token-r4l4g        kubernetes.io/service-account-token   3      17m
default-token-skhjt                kubernetes.io/service-account-token   3      38m
kubernetes-dashboard-certs         Opaque                                2      9m10s
kubernetes-dashboard-csrf          Opaque                                1      38m
kubernetes-dashboard-key-holder    Opaque                                2      38m
kubernetes-dashboard-token-qfzqk   kubernetes.io/service-account-token   3      38m
[root@c-3-102 ~]# 

//删除secret certs
[root@c-3-102 key]# kubectl delete secret        kubernetes-dashboard-certs    -n kubernetes-dashboard 

//新创建secret certs
[root@c-3-102 key]# kubectl create secret generic kubernetes-dashboard-certs  --from-file=dashboard.key --from-file=dashboard.crt -n  kubernetes-dashboard
```
#删除当前dashboard pod
```
[root@c-3-102 key]# kubectl get pods -n kubernetes-dashboard
NAME                                         READY   STATUS    RESTARTS   AGE
dashboard-metrics-scraper-6cbcff8d57-c2wzh   1/1     Running   0          29m
kubernetes-dashboard-6fd5d88555-9k2ql        1/1     Running   0          29m
[root@c-3-102 key]# 
[root@c-3-102 key]# kubectl delete pods/kubernetes-dashboard-6fd5d88555-9k2ql   -n kubernetes-dashboard
pod "kubernetes-dashboard-6fd5d88555-9k2ql" deleted

//根据deployment自动修复不存在的pod
[root@c-3-102 key]# kubectl get pods -n kubernetes-dashboard
NAME                                         READY   STATUS    RESTARTS   AGE
dashboard-metrics-scraper-6cbcff8d57-c2wzh   1/1     Running   0          30m
kubernetes-dashboard-6fd5d88555-kcfff        1/1     Running   0          10s
[root@c-3-102 key]# kubectl logs -n kubernetes-dashboard -f pods/kubernetes-dashboard-6fd5d88555-kcfff
```

#打开地址查看日志
https://192.168.3.102:30000/#/login
```
2020/06/14 08:21:57 [2020-06-14T08:21:57Z] Outcoming response to 10.10.110.128:55018 with 200 status code
```


## 07、 rancher
https://docs.rancher.cn/  
https://rancher2.docs.rancher.cn/docs/releases/v2.3.5/

#run rancher v2.3.5
```
//master-nodes
docker run -d --restart=unless-stopped -p 80:80 -p 443:443 rancher/rancher:v2.3.5
```

#set admin passwd
```
https://192.168.3.102/
admin/admin    //仅作为内部联调测试使用
```
#集群导入，并按照提示执行对应的命令
```
//rolebinding
[root@c-3-102 ~]# kubectl create clusterrolebinding cluster-admin-binding --clusterrole cluster-admin --user rancher-admin

//apply yaml
[root@c-3-102 ~]# wget  --no-check-certificate  -O r.yaml  https://192.168.3.102/v3/import/vkxfxkvbcvtkj2fdz8hkkbfmpp6z77dr2qffjkw
dx7lrdftx86vbld.yaml

[root@c-3-102 ~]# kubectl apply -f r.yaml 
```

#error
```
//浏览器显示，清空浏览器缓存
Network request failed
```